{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "from torch.autograd import Variable\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "STEP 1: LOADING DATASET\n",
    "'''\n",
    " \n",
    "train_dataset = dsets.MNIST(root='./MNIST-data', \n",
    "                            train=True, \n",
    "                            transform=transforms.ToTensor(),\n",
    "                            download=True)\n",
    " \n",
    "test_dataset = dsets.MNIST(root='./MNIST-data', \n",
    "                           train=False, \n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim, \n",
    "                algorithm_name='LogisticRegression',\n",
    "                train_batch_size=1000, num_epochs=10,\n",
    "                learning_rate=0.001, optimizer=torch.optim.Adam):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        parameters = self.linear.parameters()\n",
    "        algorithm_to_loss = {\n",
    "            'LogisticRegression': nn.CrossEntropyLoss(),\n",
    "            'SVM': self.hingeLoss}\n",
    "        \n",
    "        if not any(algorithm_name==algorithm\n",
    "                   for algorithm in algorithm_to_loss.keys()):\n",
    "            raise ValueError ('{} not currently supported', algorithm_name)\n",
    "        else:\n",
    "            self.criterion = algorithm_to_loss[algorithm_name]\n",
    "        \n",
    "        self.batch_size = train_batch_size\n",
    "        self.num_epochs = num_epochs\n",
    "        self.learning_rate = learning_rate\n",
    "        self.optimizer = optimizer\n",
    "             \n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "    \n",
    "    def hingeLoss(self, logits, targets):\n",
    "        \n",
    "        zero = torch.Tensor([0]) \n",
    "        targets = targets.long()\n",
    "        score_target_class = logits.gather(1, targets.view(-1,1))  # scores of the target class\n",
    "        targets = targets.view(-1,1)\n",
    "        ones = torch.Tensor([1])\n",
    "        loss = torch.sum(torch.max(zero, logits - score_target_class + 1.0), dim =1)\n",
    "        loss = loss - ones\n",
    "        loss = torch.mean(loss) # Getting the mean loss\n",
    "        return loss\n",
    "    \n",
    "    def fit_and_evaluate(self, model, train_dataset, test_dataset):\n",
    "        \n",
    "        optimizer = self.optimizer(model.parameters(), lr=self.learning_rate)\n",
    "        \n",
    "        train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=self.batch_size, \n",
    "                                           shuffle=True)\n",
    "        \n",
    "        for epoch in range(self.num_epochs):\n",
    "            for images, labels in train_loader:\n",
    "                images = Variable(images.view(-1, 28*28))\n",
    "                labels = Variable(labels)\n",
    "\n",
    "                # Clear gradients w.r.t. parameters\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass to get output/logits\n",
    "                outputs = self.forward(images)\n",
    "\n",
    "                # Calculate Loss: softmax --> cross entropy loss\n",
    "                loss = self.criterion(outputs, labels)\n",
    "\n",
    "                # Getting gradients w.r.t. parameters\n",
    "                loss.backward()\n",
    "\n",
    "                # Updating parameters\n",
    "                optimizer.step()\n",
    "            \n",
    "            test_images = Variable(test_dataset.test_data.view(-1, 28*28))\n",
    "            outputs = self.forward(test_images.type(torch.FloatTensor))\n",
    "\n",
    "            # Get predictions from the maximum value\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            accuracy = 100 * (predicted.cpu() == \n",
    "                              test_dataset.test_labels.cpu()).sum() / (\n",
    "                                len(test_dataset.test_labels))\n",
    "\n",
    "            # Print Loss\n",
    "            print('Epoch: {}. Training Loss: {}. Test Accuracy: {}'.format(\n",
    "                            epoch+1, loss.data, accuracy))\n",
    "           \n",
    "    def perform_adversarial_attack(self, model):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 28*28\n",
    "output_dim = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Training Loss: 0.9019647240638733. Test Accuracy: 83\n",
      "Epoch: 2. Training Loss: 0.6284455060958862. Test Accuracy: 86\n",
      "Epoch: 3. Training Loss: 0.5312653183937073. Test Accuracy: 88\n",
      "Epoch: 4. Training Loss: 0.4383023679256439. Test Accuracy: 89\n",
      "Epoch: 5. Training Loss: 0.4116615056991577. Test Accuracy: 89\n",
      "Epoch: 6. Training Loss: 0.4236544370651245. Test Accuracy: 90\n",
      "Epoch: 7. Training Loss: 0.35918644070625305. Test Accuracy: 90\n",
      "Epoch: 8. Training Loss: 0.3799954354763031. Test Accuracy: 90\n",
      "Epoch: 9. Training Loss: 0.3798162639141083. Test Accuracy: 90\n",
      "Epoch: 10. Training Loss: 0.34268519282341003. Test Accuracy: 91\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(input_dim, output_dim, algorithm_name='LogisticRegression')\n",
    "model.fit_and_evaluate(model, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Training Loss: 1.2214453220367432. Test Accuracy: 85\n",
      "Epoch: 2. Training Loss: 0.8400567173957825. Test Accuracy: 88\n",
      "Epoch: 3. Training Loss: 0.6822003722190857. Test Accuracy: 89\n",
      "Epoch: 4. Training Loss: 0.6131965517997742. Test Accuracy: 90\n",
      "Epoch: 5. Training Loss: 0.5730751156806946. Test Accuracy: 90\n",
      "Epoch: 6. Training Loss: 0.5231001973152161. Test Accuracy: 90\n",
      "Epoch: 7. Training Loss: 0.43371620774269104. Test Accuracy: 90\n",
      "Epoch: 8. Training Loss: 0.4522427022457123. Test Accuracy: 90\n",
      "Epoch: 9. Training Loss: 0.44551682472229004. Test Accuracy: 90\n",
      "Epoch: 10. Training Loss: 0.4999028444290161. Test Accuracy: 90\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(input_dim, output_dim, algorithm_name='SVM')\n",
    "model.fit_and_evaluate(model, train_dataset, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
